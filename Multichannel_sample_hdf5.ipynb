{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select, make cutouts and save the training sample for feature extraction and GAN\n",
    " from the GOODS-S field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy.io.fits as pyfits\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.wcs as wcs\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "import h5py\n",
    "\n",
    "\n",
    "def radec2xy(ra,dec,wc):\n",
    "    coords = SkyCoord(ra,dec, unit='deg')\n",
    "    a=wcs.utils.skycoord_to_pixel(coords, wc, origin=0,mode=u'wcs')\n",
    "    return a[0],a[1]\n",
    "    \n",
    "def cut(ra,dec,andaze,filename):\n",
    "    '''gets coordinates of the galaxy and the filter to return a cutout\n",
    "    (also called a postage stamp) of the galaxy with given size'''\n",
    "    hdr = pyfits.getheader(filename)\n",
    "    w = wcs.WCS(hdr)\n",
    "    x,y=radec2xy(ra,dec,w)\n",
    "    x,y=np.int(x),np.int(y)\n",
    "    im=pyfits.getdata(filename)[y-andaze:y+andaze,x-andaze:x+andaze]\n",
    "    return im\n",
    "\n",
    "def brightest_center(im, r = 10):\n",
    "    \n",
    "    '''This function is to check whether the central object of the \n",
    "    image is the brightest compared to its neighbors in the given cutout.\n",
    "    Central is defined with a 10x10 pixel square in the center'''\n",
    "    \n",
    "    a0,a1 = np.unravel_index(np.argmax(im, axis=None), im.shape)\n",
    "    ans = False\n",
    "    if ((a0>((im.shape[0]-r)/2)) & (a0<((im.shape[0]+r)/2)) & (a1>((im.shape[1]-r)/2)) & (a1<((im.shape[0]+r)/2))):\n",
    "        ans = True\n",
    "    \n",
    "    return ans\n",
    "\n",
    "imdir = '/Users/hnayyeri/Desktop/GOODS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3156\n"
     ]
    }
   ],
   "source": [
    "# selecting sample based on brightness, distance and size\n",
    "gs = pyfits.getdata('input_goods_south/gds.fits')\n",
    "sel1 = (gs['zbest']>0.01)&(gs['zbest']<2.0)&(gs['CLASS_STAR']<0.9)&(gs['Hmag']<25.)&(gs['ISOAREA_IMAGE_F160W']>=100)\n",
    "redshifts,ra1,dec1 = (gs['zbest'][sel1]),(gs['RA_1'][sel1]),(gs['DEC_1'][sel1])\n",
    "\n",
    "print (len(gs[sel1]))\n",
    "\n",
    "sample_size = len(gs[sel1])\n",
    "image_size = 28\n",
    "cut_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 500/3156\n",
      "Train data: 1000/3156\n",
      "Train data: 1500/3156\n",
      "Train data: 2000/3156\n",
      "Train data: 2500/3156\n",
      "Train data: 3000/3156\n"
     ]
    }
   ],
   "source": [
    "%rm 'Sample.hdf5'\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "tfms = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_shape = (sample_size, image_size, image_size, 1)\n",
    "\n",
    "hdf5_file = h5py.File('Sample.hdf5', mode='w')\n",
    "\n",
    "hdf5_file.create_dataset(\"train_img\", train_shape, np.float32)\n",
    "hdf5_file.create_dataset(\"train_labels\", (len(gs[sel1]),), np.float32)\n",
    "hdf5_file[\"train_labels\"][...] = redshifts\n",
    "\n",
    "for i in range(sample_size):\n",
    "    # print how many images are saved every 500 images\n",
    "    if i % 500 == 0 and i > 1:\n",
    "        print ('Train data: {}/{}'.format(i, sample_size))\n",
    "\n",
    "    \n",
    "    # cut and preprocessing \n",
    "    data = np.arcsinh(cut(ra1[i],dec1[i],cut_size,imdir+'goodss_all_acs_wfc_f775w_060mas_v1.5_drz.fits'))\n",
    "    data_pro = tfms((255.0 / (data.max()+0.1) * (data - data.min())).astype(np.uint8))\n",
    "\n",
    "    # save the image \n",
    "    hdf5_file[\"train_img\"][i,...] = data_pro.reshape(image_size,image_size,1)\n",
    "\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['train_img', 'train_labels']>\n",
      "(3156, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf = h5py.File('Sample.hdf5', 'r')\n",
    "\n",
    "print(hf.keys())\n",
    "\n",
    "boz =np.random.randint(1,sample_size)\n",
    "mm = hf['train_img'][boz,:,:,0]\n",
    "plt.imshow(mm,origin='lower')\n",
    "plt.axis('off')\n",
    "\n",
    "x_train, y_train = hf['train_img'], hf['train_labels']\n",
    "print(x_train.shape)\n",
    "plt.savefig('galaxy.jpg')\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2321\n"
     ]
    }
   ],
   "source": [
    "# selecting sample based on brightness, distance and size\n",
    "gs = pyfits.getdata('input_goods_south/gds.fits')\n",
    "sel1 = (gs['zbest']>0.01)&(gs['zbest']<1.0)&(gs['CLASS_STAR']<0.9)&(gs['Hmag']<25.)&(gs['ISOAREA_IMAGE_F160W']>=50)\n",
    "\n",
    "sample_size = len(gs[sel])\n",
    "image_size = 64\n",
    "cut_size = 32\n",
    "ra1,dec1,red1 = gs['RA_1'][sel1],gs['DEC_1'][sel1],gs['zbest'][sel1]\n",
    "mass1,sfr1 = gs['M_neb_med_lin'][sel1], gs['SFR_13a_tau'][sel1]\n",
    "urest1,vrest1,jrest1 = gs['restUXbessel'][sel1],gs['restVbessel'][sel1],gs['restJpalomar'][sel1]\n",
    "\n",
    "# furthur cut on brightest galaxy being at the center of the cutout\n",
    "redshift,ra,dec,mass,sfr,urest,vrest,jrest = [],[],[],[],[],[],[],[]\n",
    "for i in range(sample_size):\n",
    "    dat = cut(ra1[i],dec1[i],cut_size,imdir+'goodss_all_acs_wfc_f850l_060mas_v1.5_drz.fits')\n",
    "    if (brightest_center(dat)):\n",
    "        redshift.append(red1[i])\n",
    "        ra.append(ra1[i])\n",
    "        dec.append(dec1[i])\n",
    "        mass.append(mass1[i])\n",
    "        sfr.append(sfr1[i])\n",
    "        urest.append(urest1[i])\n",
    "        vrest.append(vrest1[i])\n",
    "        jrest.append(jrest1[i])\n",
    "\n",
    "sample_size = len(redshift)\n",
    "print (sample_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 500/2321\n",
      "Train data: 1000/2321\n",
      "Train data: 1500/2321\n",
      "Train data: 2000/2321\n"
     ]
    }
   ],
   "source": [
    "# three color galaxies in HST F435W, F850lp, and F160W with physical properties as labels\n",
    "%rm 'Sample_color.hdf5'\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "tfms = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_shape = (sample_size, image_size, image_size, 3)\n",
    "\n",
    "hdf5_file = h5py.File('Sample_color.hdf5', mode='w')\n",
    "\n",
    "hdf5_file.create_dataset(\"train_img\", train_shape, np.float32)\n",
    "hdf5_file.create_dataset(\"train_labels\", (len(gs[sel1]),6), np.float32)\n",
    "\n",
    "for i in range(sample_size):\n",
    "    # print how many images are saved every 500 images\n",
    "    if i % 500 == 0 and i > 1:\n",
    "        print ('Train data: {}/{}'.format(i, sample_size))\n",
    "\n",
    "    files = ['goodss_all_acs_wfc_f435w_060mas_v1.5_drz.fits',\n",
    "            'goodss_all_acs_wfc_f850l_060mas_v1.5_drz.fits',\n",
    "            'goodss_all_wfc3_ir_f160w_060mas_v1.0_drz.fits']\n",
    "    # cut and preprocessing \n",
    "    data_pro = np.zeros((image_size,image_size,3))\n",
    "    for j in range(3):\n",
    "        data = np.arcsinh(cut(ra1[i],dec1[i],cut_size,imdir+files[j]))\n",
    "        data_pro[...,j] = tfms((255.0 / (data.max()+0.1) * (data - data.min())).astype(np.uint8))\n",
    "\n",
    "    # save the image \n",
    "    hdf5_file[\"train_img\"][i,...] = data_pro\n",
    "    hdf5_file[\"train_labels\"][i,...] = [redshift[i],mass[i],sfr[i],urest[i],vrest[i],jrest[i]]\n",
    "\n",
    "\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
